1. The times taken for the reddit_averages.py file to run using certain directories and restrictions are
the following: it took 52.42 seconds when using the reddit-0 directory; it took 103.91 seconds when using the reddit-2b
directory with a schema; it took 137.65 seconds when using the reddit-2b directory without a schema; it took
116.31 seconds when using the reddit-2b directory with a schema and caching.

2. Taking the difference of the time taken using the reddit-2b directory without and with a schema, we see that
it takes approximately 33 seconds to read the data into a DataFrame. When taking the difference of the time to
process reddit-2b with a schema and reddit-0, we see that the time taken to read and calculate the averages is
approximately 52 seconds. Considering that 33 of the 52 seconds is used to read the data, we see that
only 19 seconds is devoted to calculating the averages. Therefore, we can conclude that most of the time
taken to process the reddit-2b data is associated with reading the data.

3. Within the wikipedia_popular.py file, I placed the call to the cache method after filtering the
wikipedia pages written in english and those whose title does not start with "Special:" or is "Main_Page".